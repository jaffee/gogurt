* Overview

The basic idea here is for me to write a little bit of go code every
day, and then write about what I did. The rules are to do SOMETHING
every day that involves pushing some code to github. If I don't, my
wife gets ten bucks for her clothes shopping fund. If I do, then for
every 7 day streak, I get ten bucks for my 'buy whatever I want'
fund. The purpose is threefold:

1. Learn go.
2. Have consistent github activity.
3. Improve writing and blogging skills.

Hopefully soon, pushing code and posts will automatically update the
site, and I'll have some pretty way to display the code I wrote along
side the post.


** Day 1
Got basic structure set up - mostly looking here:
https://golang.org/doc/code.html

Basic HTTP server running - http://golang.org/doc/articles/wiki/

** Day 2
Today I added some html files, still loosely following the "Writing
Web Applications" page from yesterday.

Go's 'html/template' works by passing a struct to the template's
Execute method which contains fields named the same as the variables
in the template. I haven't played around with what happens if you have
stuff in your struct that isn't in the template or vice versa.

So now I have a root page and another page at '/day/' - goes handlers
seem to do routing by a variant of longest prefix matching, as the '/'
url matches all, but the '/day/' gets used if the URL starts with
/day/ (or just /day interestingly). But if you have handler for
'/day', that will only match '/day'.

After that was going, I started poking around at Github's API - the
idea is going to be to automatically create the page for whatever date
is specified in the URL, i.e. '/day/20150319', by pulling the post and
any commits for the day from Github. Once the day is over, I'll cache
that data in a file so that we don't need to pound github on every
request.

It looks like github's api will be fairly simple - no auth appears to
be necessary, and the URL structure is straightforward. I've got some
ideas for parsing JSON in go based on some things that were said at
the ATX golang meetup, so we'll see how that goes.

** Day 3
Switched gears and did this: [[http://github.com/jaffee/robpike.io]]

** Day 4
Started on =github.go= using net/http to hit the github api, and
encoding/json to read json data into defined type/structs. Not sure
how to read in something like the repos_url which is an array at the
top level... will have to play around with that.
** Day 5
Today I started integrating the github api code with the
website/server code. I had to move github.go into a github directory
in order to make go happy with my package structure, run =go build= on
the github package, then =go run= on gogurt/main.go. But I was able to
import and use functions defined in github.go from main.go, so that's
solid.

I also learned how to loop over slices in templates which used kind of
an odd syntax, but you can see it in =day.html=

I played with the time package quite a bit, getting the current time,
pulling the year, month, and day out of it, and then constructing a
new time with H,M,S set to 0 in order to get the beginning of the day.

I also figured out how to parse JSON into a slice of objects which was
cool.

Tomorrow I'm going to install go auto-complete into emacs so that I
can move a bit faster on silly things like string operations, and then
have my git commits from the previous day displayed on the webpage
(pretty close right now I think).

** Day 6
Set up autocomplete in emacs with company mode and gocode. Seems to
work pretty nicely.

Figured out how to strip the {sha} part of commit urls with
strings.Replace. A little strange to me that strings themselves don't
have methods and you have to use external methods, but I know that's
just a product of too much Python.
** Day 7
Today I was pretty lame - tried breaking up the big getcommits
function, and trying to figure out a way to unmarshal json into the
correct size slice - without having to try to guess the size first.
** Day 8
Wrote a function to pretty print json using json.Indent - then started
reading "effective go".

Also made use of bytes.Buffer - will have to explore bytes lib more.
** Day 9
I've been reading about reflection as I try to figure out how
json.Unmarshal works. I want to figure out how it unmarshals json
arrays into slices so I can figure out how to allocate slices
beforehand. ...and I figured it out - Unmarshal automatically
allocates according to the documentation, so all you have to do is
declare the slice like so

** Day 10
Starting to learn the hard lessons of no generic functions in go (like
'map'). I guess it's not too bad to just write a quick for loop, and
maybe it's worth it for the type safety?

I'm thinking a Post will consist of a title and a some repositories
which I'll hard code for now, and then each repository will be a name
and some commits (all of this is on a per day basis), so each page
will be a list of repos with their commits next to them. Not sure how
I'll work the posts in yet.
#+begin_src go
	var commits_slice []commit
#+end_src

** Day 11
Whew. Big day.
1. Created a new repo which pulls all commits related to a list of
   repos for a day and writes them to a file. (This file will be
   consumed by gogurt is the plan)
2. Wrote my first go test (huge!).
3. Learned a bit about how go's package structure works. It's a bit
   limiting but I guess that's a good thing. This is the reason why I
   ended up splitting the github querying stuff into another repository.
4. Will need to pass a specific header in order to get actual diffs
   per commit - read a bit about how to do this.
5. Learned about Sprintf for easy creation of strings from various
   objects.

Tomorrow I'll either work on getting diffs, or having gogurt read the
files generated by go github.
** Day 12
Took wayyyyy too long, but I got the diffs. I figured out how to send
the header pretty quickly, but wasn't getting diffs back for quite a
while. I tried using wireshark to see if the header was getting dumped
correctly, but then got stymied by the fact that all github api
traffic happens over SSL. A brief tour down "decoding TLS traffic with
wireshark" lane convinced me that it was more trouble than it was
worth (although possible).

I ended up comparing my working curl command with my non working go
code, and realized the URLs were different. Curl was pulling a
specific commit (by sha), whereas I was still trying to pull a bunch
of commits in go. I had to refactor my code to get the list of
commits, and then pull each one separately with the correct header
set, and that worked just dandily.
** Day 13
So close. I've encountered some kind of template processing bug while
attempting to get unmarshaled json read from a file rendered as a
template.

It appears to be having trouble escaping something, but what's odd is
that the bug occurs even when I take everything out of the
template. It's going to take some more digging to figure out what's
going on... guess I know what I'm doing tomorrow.
** Day 14
Alright! We have a page. With CSS. What great joy!

It turned out that my horrible template bug from yesterday was because
I was running gogurt from a different directory and it couldn't find
the .html file... doh.

Then I couldn't get any browsers to use my css file which after a
while I realized was because I was serving the file by reading the
bytes and then just giving it to the writer object. Using
http.Servefile seems to set the headers properly and the CSS got
applied.
** Day 15
Made use of ioutil.ReadDir to do effectively do an `ls` on the
directory with all the activity files, and then used some stuff from
the strings package to get just the date part of the filename and gave
the list of those to the root template to populate the root page with
links to all the date pages.

Pretty straightforward day... getting more comfortable in go, no major
problems.

I've got some grand ideas for a chatbot sometime soon, and I'd also
like to do a file watcher that will rebuild my code and restart the
server whenever files change - Flask style (probably 170 other web
frameworks too).

** Day 16
Started doing some work on the github fetcher - I'd like to make it a
long running process that repeatedly checks to see what days it needs
to fetch, and then does so. I'd also like it to be resilient to
problems with the github api - it going down, rate limiting, etc.

Today I converted all my function calls to explicitly return error
values so that I could see what was going on higher up the stack and
decide whether to wait and retry or not. In retrospect, I think it
would be a lot cleaner to panic and defer, but we'll see.

Tomorrow I'd like to implement the "long runningness" and
resilience. I'll need to make a checker that figures out what days
need to be pulled based on current files and current date, and then
the puller which continuously tries to pull down all the stuff
necessary for a given day, intelligently waiting and retrying as
necessary.
** Day 17
Today I wrote the checker that figures out what days are not
represented among the activity files in the time range we're looking
at. It looks a little complex, but I've got some ideas to break it
out. Ideally, I think it will take in just a list and a start and end
date and will return a list of the days not represented in the input
list - I'll take care of all the I/O and normalization outside of
it.

Writing this function made me feel like Go is a lot more verbose than
Python - that may be partially due to the fact that I don't know the
right way to do things, but I think it also is likely due to lots of
explicit error handling and type converting. Because functions like
Atoi return both an error val and an int, you can't call them inline
in a function call, and because you have to handle the error, that
means that what was once one line is now at least 3.

I have also noticed however that bugs are pretty easy to track down -
especially when you handle errors (if you don't it's a nightmare - see
the 'template' bug from a few days ago). Where in Python I usually
resort to a debugger as soon as something goes wrong, in Go the errors
have been pretty straightforward based on the message and line
number. The number of things that can go wrong on any one line is
tightly constrained due to being able to do less on a line, and all
the type constraints that you know were enforced at compile time.

It's a different paradigm than I'm used to, and it's a little annoying
when your trying to throw down some code quickly, but it's also more
predictable time-wise, and I think it will pay off as codebases grow
larger.

** Day 18
Today I wrote the main loop for the long running process behavior and
am testing it... as we speak. er... as I write.

To do this, I implemented the behavior for tolerating rate limits -
this involves checking the http status code and then reading the
header to see when the rate limit will be lifted, and sleeping until
then. I implemented this behavior right inside the functions that make
the http request, so they can potentially sleep for a long time - this
is probably bad design, but hey... put it on the list of things to
refactor.

I ran into a lot of silly type problems, so I'm getting more facile at
converting everything properly. Usually you can just call the name of
the type like a function to convert the value i.e. int64(someint),
although this isn't always possible. I hope to be able to write a more
coherent explanation of why not soon.

-- time passes --

Ok, it finished its first round... it created all the right files, but
they're all empty.... sigh. I'll have to track this one down tomorrow.

** Day 19
Guess I fixed the bug. I definitely fixed another bug, and now things
seem to be working. My code to determine if the previous date was 1
day behind the current date kinda sucked, so I wrote an actual
function and test that seems to work very well. This was helped by the
fact that go Time objects roll over in a nice way - i.e. December 32
is January 1st of the next year.

Re-running the whole thing now - ratelimit should reset in a few
minutes and we'll see if that works.

... and it seems to have - and it ran out again. Not sure how it needs
so many requests. I'm sleepy.


* Future work ideas
- get code running on some hosting
- set up git hooks to restart it every time there's a push
- write a supervisor in go to restart it if it dies.
